{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a34d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1c462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/metropolisjenensis/data_for_prob_ML/refs/heads/main/weatherAUS.csv\"\n",
    "df= pd.read_csv(url, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddaf9cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60789b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    75625.000000\n",
       "mean         7.611178\n",
       "std          3.785483\n",
       "min          0.000000\n",
       "25%          4.800000\n",
       "50%          8.400000\n",
       "75%         10.600000\n",
       "max         14.500000\n",
       "Name: Sunshine, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sunshine\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b0c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with too many missing values\n",
    "threshold = 0.3  # 30% missing allowed\n",
    "df_clean = df.loc[:, df.isnull().mean() < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c958b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing target\n",
    "df_clean = df_clean.dropna(subset=[\"RainTomorrow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed23ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "df_clean[\"RainTomorrow\"] = df_clean[\"RainTomorrow\"].map({\"No\": 0, \"Yes\": 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "730d6cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Date' (not useful for this task)\n",
    "df_clean = df_clean.drop(columns=[\"Date\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac665f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numerical values with column median\n",
    "for col in df_clean.select_dtypes(include=[np.number]).columns:\n",
    "    df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d0dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "cat_cols = df_clean.select_dtypes(include=[\"object\"]).columns\n",
    "for col in cat_cols:\n",
    "    df_clean[col] = LabelEncoder().fit_transform(df_clean[col].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84b92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df_clean.drop(columns=[\"RainTomorrow\"])\n",
    "y = df_clean[\"RainTomorrow\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c5533e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113754, 17), (28439, 17))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Standardize features for logistic regression and autoencoder\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc955b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092cc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\konst\\miniconda3\\envs\\CER24\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:40:50] WARNING: C:\\b\\abs_52v3kadn8m\\croot\\xgboost-split_1748343554494\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[20913,  1151],\n",
       "        [ 2871,  3504]], dtype=int64),\n",
       " 0.8585744927740075,\n",
       " array([[20934,  1130],\n",
       "        [ 3345,  3030]], dtype=int64),\n",
       " 0.8426456626463659)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Train XGBoost Classifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_preds = xgb_model.predict(X_test)\n",
    "\n",
    "# Train Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate both models\n",
    "xgb_cm = confusion_matrix(y_test, xgb_preds)\n",
    "xgb_acc = accuracy_score(y_test, xgb_preds)\n",
    "xgb_report = classification_report(y_test, xgb_preds, output_dict=True)\n",
    "\n",
    "lr_cm = confusion_matrix(y_test, lr_preds)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "lr_report = classification_report(y_test, lr_preds, output_dict=True)\n",
    "\n",
    "xgb_cm, xgb_acc, lr_cm, lr_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizerss\n",
    "# Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "encoding_dim = 8\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "decoded = Dense(input_dim, activation='linear')(encoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "X_train_0 = X_train[y_train == 0]\n",
    "autoencoder.fit(X_train_0, X_train_0, epochs=20, batch_size=64, shuffle=True, verbose=0)\n",
    "\n",
    "# Predictions and evaluation\n",
    "X_test_pred = autoencoder.predict(X_test, verbose=0)\n",
    "reconstruction_error = np.mean(np.power(X_test - X_test_pred, 2), axis=1)\n",
    "threshold = np.percentile(reconstruction_error[y_test == 0], 95)\n",
    "autoencoder_preds = (reconstruction_error > threshold).astype(int)\n",
    "\n",
    "ae_cm = confusion_matrix(y_test, autoencoder_preds)\n",
    "ae_acc = accuracy_score(y_test, autoencoder_preds)\n",
    "ae_report = classification_report(y_test, autoencoder_preds, output_dict=True)\n",
    "\n",
    "ae_cm, ae_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CER24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
